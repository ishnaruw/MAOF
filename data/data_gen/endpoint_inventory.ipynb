{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690f5d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolBench root: /Users/ishwaryapns/Documents/Thesis/MAOF/data/raw/toolbench/data/toolenv/tools\n",
      "Output dir: /Users/ishwaryapns/Documents/Thesis/MAOF/data/processed/api_catalog_sample10\n"
     ]
    }
   ],
   "source": [
    "# Build API repo JSONL (with & without QoS) from ToolBench (all categories) + WS-Dream\n",
    "\n",
    "from pathlib import Path\n",
    "import json, re, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------- Paths (adjust if needed) ----------\n",
    "TOOLBENCH_ROOT = Path(\"/Users/ishwaryapns/Documents/Thesis/MAOF/data/raw/toolbench/data/toolenv/tools\")\n",
    "\n",
    "# WS-Dream matrices (txt/csv; delimiter auto-detected)\n",
    "WSD_RT = Path(\"../raw/wsdream/dataset1/rtMatrix.txt\")\n",
    "WSD_TP = Path(\"../raw/wsdream/dataset1/tpMatrix.txt\")\n",
    "\n",
    "# Output folder and filenames\n",
    "OUT_DIR = Path(\"../processed/api_catalog_sample10\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NO_QOS_OUT = OUT_DIR / \"api_repo.no_qos.jsonl\"\n",
    "WITH_QOS_OUT = OUT_DIR / \"api_repo.with_qos.jsonl\"\n",
    "\n",
    "# Reproducible mapping of QoS columns to endpoints\n",
    "random.seed(42)\n",
    "\n",
    "print(\"ToolBench root:\", TOOLBENCH_ROOT.resolve())\n",
    "print(\"Output dir:\", OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "139a7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matrix(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Auto-detect delimiter (comma/space/tab). No header.\"\"\"\n",
    "    return pd.read_csv(path, header=None, sep=None, engine=\"python\")\n",
    "\n",
    "def slug(text: str) -> str:\n",
    "    s = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", (text or \"\").strip().lower()).strip(\"_\")\n",
    "    return s[:64] if s else \"x\"\n",
    "\n",
    "def safe_get(d, key, default=None):\n",
    "    return d.get(key, default) if isinstance(d, dict) else default\n",
    "\n",
    "def yield_endpoints_from_tool(tool_obj: dict, tool_base: str, category: str, file_name: str):\n",
    "    api_list = safe_get(tool_obj, \"api_list\", [])\n",
    "    if not isinstance(api_list, list):\n",
    "        return\n",
    "    for ep in api_list:\n",
    "        if not isinstance(ep, dict):\n",
    "            continue\n",
    "        name = safe_get(ep, \"name\") or \"\"\n",
    "        url = safe_get(ep, \"url\") or \"\"\n",
    "        method = safe_get(ep, \"method\") or \"\"\n",
    "        desc = safe_get(ep, \"description\") or \"\"\n",
    "\n",
    "        ep_id = f\"{tool_base}_{slug(name) or 'endpoint'}\"\n",
    "\n",
    "        yield {\n",
    "            \"api_id\": ep_id,\n",
    "            \"category\": category,\n",
    "            \"name\": name,\n",
    "            \"description\": desc,\n",
    "            \"method\": method,\n",
    "            \"url\": url,\n",
    "            \"_file\": file_name,\n",
    "            \"_tool\": tool_base,\n",
    "        }\n",
    "\n",
    "def iter_endpoints_any_json(json_path: Path, category: str):\n",
    "    try:\n",
    "        data = json.loads(json_path.read_text())\n",
    "    except Exception:\n",
    "        return\n",
    "\n",
    "    file_stem = json_path.stem\n",
    "    tool_base_default = slug(file_stem)\n",
    "\n",
    "    if isinstance(data, dict) and isinstance(data.get(\"api_list\"), list):\n",
    "        tool_base = safe_get(data, \"standardized_name\") or tool_base_default\n",
    "        yield from yield_endpoints_from_tool(data, tool_base, category, json_path.name)\n",
    "        return\n",
    "\n",
    "    if isinstance(data, dict) and isinstance(data.get(\"tools\"), list):\n",
    "        for t in data[\"tools\"]:\n",
    "            if not isinstance(t, dict): \n",
    "                continue\n",
    "            tool_base = safe_get(t, \"standardized_name\") or safe_get(t, \"name\") or tool_base_default\n",
    "            yield from yield_endpoints_from_tool(t, slug(tool_base), category, json_path.name)\n",
    "        return\n",
    "\n",
    "    if isinstance(data, dict) and isinstance(data.get(\"endpoints\"), list):\n",
    "        tool_like = {\n",
    "            \"api_list\": data[\"endpoints\"],\n",
    "            \"standardized_name\": safe_get(data, \"standardized_name\") or tool_base_default\n",
    "        }\n",
    "        yield from yield_endpoints_from_tool(tool_like, slug(tool_like[\"standardized_name\"]), category, json_path.name)\n",
    "        return\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        for idx, item in enumerate(data):\n",
    "            if isinstance(item, dict) and isinstance(item.get(\"api_list\"), list):\n",
    "                tool_base = safe_get(item, \"standardized_name\") or safe_get(item, \"name\") or f\"{tool_base_default}_{idx}\"\n",
    "                yield from yield_endpoints_from_tool(item, slug(tool_base), category, json_path.name)\n",
    "        return\n",
    "\n",
    "def compute_qos_per_column(rt_col: pd.Series, tp_col: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Compute median RT/TP and availability. If no valid values, return nulls and 0 availability.\n",
    "    \"\"\"\n",
    "    rt_valid = rt_col.replace(-1, np.nan).dropna()\n",
    "    tp_valid = tp_col.replace(-1, np.nan).dropna()\n",
    "    availability = len(rt_valid) / len(rt_col) if len(rt_col) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"rt_ms\": float(np.median(rt_valid)) if not rt_valid.empty else None,\n",
    "        \"tp_rps\": float(np.median(tp_valid)) if not tp_valid.empty else None,\n",
    "        \"availability\": round(availability, 4),\n",
    "        \"valid_qos\": not (rt_valid.empty or tp_valid.empty)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339fd698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total endpoints collected across ALL categories: 5753\n"
     ]
    }
   ],
   "source": [
    "# Walk all category folders and collect endpoints\n",
    "all_endpoints = []\n",
    "category_dirs = sorted([p for p in TOOLBENCH_ROOT.iterdir() if p.is_dir()])\n",
    "\n",
    "for cat_dir in category_dirs:\n",
    "    category = cat_dir.name\n",
    "    for jf in sorted(cat_dir.glob(\"*.json\")):\n",
    "        for ep in iter_endpoints_any_json(jf, category):\n",
    "            all_endpoints.append(ep)\n",
    "\n",
    "print(f\"Total endpoints collected across ALL categories: {len(all_endpoints)}\")\n",
    "if not all_endpoints:\n",
    "    raise SystemExit(\"No endpoints found. Check TOOLBENCH_ROOT path or JSON shapes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e74c3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique endpoints after ID de-duplication: 5753\n"
     ]
    }
   ],
   "source": [
    "seen = {}\n",
    "unique_endpoints = []\n",
    "for ep in all_endpoints:\n",
    "    api_id = ep[\"api_id\"]\n",
    "    if api_id not in seen:\n",
    "        seen[api_id] = 1\n",
    "        unique_endpoints.append(ep)\n",
    "    else:\n",
    "        seen[api_id] += 1\n",
    "        new_id = f\"{api_id}-{seen[api_id]}\"\n",
    "        ep = {**ep, \"api_id\": new_id}\n",
    "        unique_endpoints.append(ep)\n",
    "\n",
    "print(f\"Unique endpoints after ID de-duplication: {len(unique_endpoints)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9040568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS-Dream matrix: 339 users × 5826 API columns\n"
     ]
    }
   ],
   "source": [
    "rt_df = read_matrix(WSD_RT)\n",
    "tp_df = read_matrix(WSD_TP)\n",
    "\n",
    "if rt_df.shape != tp_df.shape:\n",
    "    raise ValueError(f\"RT/TP shape mismatch: {rt_df.shape} vs {tp_df.shape}\")\n",
    "\n",
    "n_users, n_cols = rt_df.shape\n",
    "print(f\"WS-Dream matrix: {n_users} users × {n_cols} API columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebfaaf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: api_repo.no_qos.jsonl  (all 5753 endpoints)\n",
      "Wrote: api_repo.with_qos.jsonl (5753 endpoints with QoS attached)\n"
     ]
    }
   ],
   "source": [
    "col_indices = list(range(n_cols))\n",
    "random.shuffle(col_indices)\n",
    "\n",
    "assigned = 0\n",
    "skipped = 0\n",
    "\n",
    "with NO_QOS_OUT.open(\"w\", encoding=\"utf-8\") as no_qos_f, \\\n",
    "     WITH_QOS_OUT.open(\"w\", encoding=\"utf-8\") as with_qos_f:\n",
    "\n",
    "    for i, ep in enumerate(unique_endpoints):\n",
    "        base = {k: v for k, v in ep.items() if not k.startswith(\"_\")}\n",
    "        no_qos_f.write(json.dumps(base, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        if i < len(col_indices):\n",
    "            c = col_indices[i]\n",
    "            qos = compute_qos_per_column(rt_df[c], tp_df[c])\n",
    "            with_qos_f.write(json.dumps({**base, \"qos\": qos}, ensure_ascii=False) + \"\\n\")\n",
    "            assigned += 1\n",
    "        else:\n",
    "            skipped += 1\n",
    "\n",
    "print(f\"Wrote: {NO_QOS_OUT.name}  (all {len(unique_endpoints)} endpoints)\")\n",
    "print(f\"Wrote: {WITH_QOS_OUT.name} ({assigned} endpoints with QoS attached)\")\n",
    "if skipped:\n",
    "    print(f\"Endpoints without QoS (no column left or invalid column): {skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b89b8bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_qos.jsonl lines: 5753\n",
      "with_qos.jsonl lines: 5753\n",
      "\n",
      "Sample no_qos:\n",
      "{\"api_id\": \"1_cent_sms_sendsms\", \"category\": \"Communication\", \"name\": \"SendSMS\", \"description\": \"Send an SMS to the USA or Canada for 1 cent, the payload should be something like;\\n\\n{\\n\\t\\\"text\\\": \\\"Your Authentication code is 14456\\\",\\n\\t\\\"phone\\\": \\\"+17047037094\\\"\\n}\", \"method\": \"POST\", \"url\": \"https://1-cent-sms.p.rapidapi.com/default/SMSLambda\"}\n",
      "{\"api_id\": \"2factor_authentication_india_send_transactional_sms\", \"category\": \"Communication\", \"name\": \"Send Transactional SMS\", \"description\": \"Send Single / Bulk Transactional Messages / Schedule SMS\", \"method\": \"POST\", \"url\": \"https://2factor.p.rapidapi.com/API//V1/293832-67745-11e5-88de-5600000c6b13/ADDON_SERVICES/SEND/TSMS\"}\n",
      "{\"api_id\": \"31events_send_native_calendar_invites_accountcreate\", \"category\": \"Communication\", \"name\": \"AccountCreate\", \"description\": \"\", \"method\": \"POST\", \"url\": \"https://pinke01-31events-auth.p.rapidapi.com/account\"}\n",
      "\n",
      "Sample with_qos:\n",
      "{\"api_id\": \"1_cent_sms_sendsms\", \"category\": \"Communication\", \"name\": \"SendSMS\", \"description\": \"Send an SMS to the USA or Canada for 1 cent, the payload should be something like;\\n\\n{\\n\\t\\\"text\\\": \\\"Your Authentication code is 14456\\\",\\n\\t\\\"phone\\\": \\\"+17047037094\\\"\\n}\", \"method\": \"POST\", \"url\": \"https://1-cent-sms.p.rapidapi.com/default/SMSLambda\", \"qos\": {\"rt_ms\": 1.3635000000000002, \"tp_rps\": 330.994, \"availability\": 0.9971, \"valid_qos\": true}}\n",
      "{\"api_id\": \"2factor_authentication_india_send_transactional_sms\", \"category\": \"Communication\", \"name\": \"Send Transactional SMS\", \"description\": \"Send Single / Bulk Transactional Messages / Schedule SMS\", \"method\": \"POST\", \"url\": \"https://2factor.p.rapidapi.com/API//V1/293832-67745-11e5-88de-5600000c6b13/ADDON_SERVICES/SEND/TSMS\", \"qos\": {\"rt_ms\": 0.309, \"tp_rps\": 9.692499999999999, \"availability\": 0.9941, \"valid_qos\": true}}\n",
      "{\"api_id\": \"31events_send_native_calendar_invites_accountcreate\", \"category\": \"Communication\", \"name\": \"AccountCreate\", \"description\": \"\", \"method\": \"POST\", \"url\": \"https://pinke01-31events-auth.p.rapidapi.com/account\", \"qos\": {\"rt_ms\": 0.132, \"tp_rps\": 22.727, \"availability\": 0.9853, \"valid_qos\": true}}\n"
     ]
    }
   ],
   "source": [
    "no_qos_lines = sum(1 for _ in NO_QOS_OUT.open())\n",
    "with_qos_lines = sum(1 for _ in WITH_QOS_OUT.open())\n",
    "print(\"no_qos.jsonl lines:\", no_qos_lines)\n",
    "print(\"with_qos.jsonl lines:\", with_qos_lines)\n",
    "\n",
    "print(\"\\nSample no_qos:\")\n",
    "for i, line in enumerate(NO_QOS_OUT.open()):\n",
    "    if i == 3: break\n",
    "    print(line.strip())\n",
    "\n",
    "print(\"\\nSample with_qos:\")\n",
    "for i, line in enumerate(WITH_QOS_OUT.open()):\n",
    "    if i == 3: break\n",
    "    print(line.strip())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
